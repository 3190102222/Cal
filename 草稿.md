 $X$是$(\Omega,\mathcal{F},P)$概率空间上的可积随机变量，$\mathcal{G}$是$\mathcal{F}$的子$\sigma-field$，随机变量$Y$称为是$X$关于$\mathcal{G}$的条件期望，记为$E[X|\mathcal{G}]$，如果$Y$满足以下两个性质：
(1)$Y$是$\mathcal{G}$可测的并且$Y$是可积的
(2)$\forall G \in \mathcal{G}$，$\int_{G} Y \, dP = \int_{G} X \, dP$



设$M$是希尔伯特空间$\mathcal{U}$的闭子空间，则$\mathcal{U}$中的任意元素$x$，有如下唯一的正交分解：
$$
  x=y+z，其中y\in M，z \in M^\bot  
$$
$y$称为$x$在$M$中的正交投影



概率空间$(\Omega,\mathcal{F},P)$，$L^2(\Omega,\mathcal{F},P)$表示$(\Omega,\mathcal{F},P)$上所有平方可积的随机变量的集合。令$M := L^2(\Omega,\mathcal{G},P)$，对于$\xi \in L^2(\Omega,\mathcal{F},P)$，定义$\zeta$为$\xi$在$M$中的正交投影。可以证明：$\zeta = E[\xi|\mathcal{G}]$.，进一步，对于$L^1(\Omega,\mathcal{F},P)$，我们可以利用$L^2(\Omega,\mathcal{F},P)$的稠密性，将这个定义延拓
proof
1.首先说明$M$是闭子空间：
任意收敛随机变量序列$\{\xi_{n}\},\xi_{n} \in M,(即\xi_{n} \in \mathcal{G}), \xi=\lim\limits_{ n \to \infty } \xi_n  \in \mathcal{G}$，另外，由Fatou引理，$\xi$平方可积，$\therefore \xi = \lim\limits_{ n \to \infty }\xi_{n} \in M$
2.对于$\xi \in L^2(\Omega,\mathcal{F},P)$，$\zeta$为正交投影。下面证明：$\zeta = E[\xi|\mathcal{G}]$.
$\forall G \in \mathcal{G},\int_{G} \xi - \zeta \, dP=\int (\xi - \zeta) I_{G} \, dP=0$，其中，$I_{G}$是$G$上的示性函数，$I_{G}\in M$，上式第二个等号由正交投影的定义给出
3.利用稠密性进行延拓：
对于$\xi \in L^1(\Omega,\mathcal{F},P)$，取$\xi_{n} \to \xi,\xi_{n} \in L^2(\Omega,\mathcal{F},P)$，$\zeta_{n}$为$\xi_{n}$在$M$中的正交投影。$\xi_{n} = \zeta_{n}+\eta_{n},||\zeta_{m}-\zeta_{n}||_{2} \le ||\xi_{m}-\xi_{n}||_{2}$。所以$\zeta_{n}$在$L^1(\Omega,\mathcal{G},P)$中存在极限$\zeta$。
1)首先说明$\zeta$不依赖于$\{\xi_{n}\}$的选取：
假设有另一个序列$\{\xi'_{n}\},\xi'_{n} \to \xi$，则$\xi'_{n}-\xi_{n}\to 0,\therefore \zeta'_{n}-\zeta_{n}\to 0,\therefore \zeta'=\zeta$.这里的等于号是在$L^1$意义下的，也等价于$a.e.$意义下
2)然后说明$\int_{G}\xi- \zeta \, dP=0$：
我们有$\int_{G} \xi_{n}-\zeta_{n} \, dP=0$，对$n$取极限得$\int_{G} \xi-\zeta \, dP$




$X_{1},X_{2},\cdots$是$(\Omega,\mathcal{F},P)$上的随机变量序列，$\mathcal{F}_{1},\mathcal{F}_{2},\cdots$是$\mathcal{F}$的子$\sigma-fields$的序列。$\{(X_{n},\mathcal{F}_{n}):n=1,2,\cdots\}$是鞅如果以下四个条件成立：
1.域流的信息是累加的，即$n+1$时刻的信息不少于$n$时刻的信息：$\mathcal{F}_{n} \subset \mathcal{F}_{n+1}$
2.$X_{n}$依赖于$\mathcal{F}_{n}$的信息，即$X_{n}$是$\mathcal{F}_{n}$可测的
3.$X_{n}$是可积的，即$E[|X_{n}|]<\infty$
4.在几乎处处的意义下，$E[X_{n+1}|\mathcal{F}_{n}]=X_{n}$



$X_{1},X_{2},\cdots$是$(\Omega,\mathcal{F},P)$上的随机变量序列，$\mathcal{F}_{1},\mathcal{F}_{2},\cdots$是$\mathcal{F}$的子$\sigma-fields$的序列。$\{(X_{n},\mathcal{F}_{n}):n=1,2,\cdots\}$是下鞅如果以下四个条件成立：
1.域流的信息是累加的，即$n+1$时刻的信息不少于$n$时刻的信息：$\mathcal{F}_{n} \subset \mathcal{F}_{n+1}$
2.$X_{n}$依赖于$\mathcal{F}_{n}$的信息，即$X_{n}$是$\mathcal{F}_{n}$可测的
3.$X_{n}$是可积的，即$E[|X_{n}|]<\infty$
4.在几乎处处的意义下，$E[X_{n+1}|\mathcal{F}_{n}]\ge X_{n}$


$\{X_{t},t \in \mathbb{R}_{\ge 0}\}$是$(\Omega,\mathcal{F},P)$上的随机变量序列，$\{\mathcal{F}_{t},t \in \mathbb{R}_{\ge 0}\}$是$\mathcal{F}$的子$\sigma-fields$的序列。$\{(X_{t},\mathcal{F}_{t}),t \in \mathbb{R}_{\ge 0}\}$是鞅如果以下四个条件成立：
1.域流的信息是累加的：$\mathcal{F}_{s} \subset \mathcal{F}_{t},s \le t$
2.$X_{t}$依赖于$\mathcal{F}_{t}$的信息，即$X_{t}$是$\mathcal{F}_{t}$可测的
3.$X_{t}$是可积的，即$E[|X_{t}|]<\infty$
4.在几乎处处的意义下，$E[X_{t}|\mathcal{F}_{s}]=X_{s},\forall s \le t$

关于连续鞅，一般要求域流满足右连续条件：
$$
  \mathcal{F}_{s+} \overset{def}{=} \bigcap\limits_{t>s}  \mathcal{F}_{t} = \mathcal{F}_{s}  
$$



对于鞅$\{(X_{t},\mathcal{F}_{t}),t \in \Lambda\}$，其中$\Lambda$是时间的集合，和有界停时$\tau$，停止过程$\{Y_{t} = X_{t \wedge \tau},t \in \Lambda\}$也是一个鞅。


FDR的背景
在多元假设检验问题中，我们很多时候考虑的是发生错误的概率(FWER,family wise error rate)。
多元假设检验的一个简单任务是全局假设检验。我们检验全局的假设$$H_{0}=\bigcap\limits_{i=1}^{n}H_{0,i}$$我们拒绝$H_{0}$，如果存在某一个$i$，我们在第$i$个假设检验中拒绝了原假设$H_{0,i}$
比较经典的检验方法有Bonferroni方法。
Bonferroni方法：
假设对于每一个零假设$H_{0,i}$，我们有一个p-value $p_{i}\sim U[0,1]$. 对于显著性水平$\alpha$，Bonferroni方法拒绝全局零假设当且仅当
$$\min\limits_{i}p_{i} \le \frac{\alpha}{n}$$
$$
    弃真概率
    =P_{H_{0}}(第一类错误)
    =P_{H_{0}}\left( \bigcup\limits_{i=1}^{n}p_{i} \le \frac{\alpha}{n} \right)
    \le \sum\limits_{ i = 1 }^{ n }P_{H_{0}}\left( p_{i}\le \frac{\alpha}{n} \right)=\sum\limits_{ i = 1 }^{ n } \frac{\alpha}{n} = \alpha
$$
这说明Bonferroni方法确实可以控制第一类错误的概率，但是这种方法的检验功效是很差的。直观感受就是，为了使弃真概率$\le \alpha$，对于每一个单独的假设检验都要求$p_{i} \le \frac{\alpha}{n}$，当$n$很大时，我们的要求太严格了。

考虑独立的高斯序列模型(Gaussian Sequence Model)：
$$Y_{i}\overset{iid}{\sim} \mathcal{N}(\mu_{i},1)$$
我们要检验的是$H_{0,i}:\mu_{i} = 0 \leftrightarrow H_{1,i}:\mu_{i}\ge 0$
全局的零假设是$\forall i,\mu_{i}=0$，全局的备择假设是$\exists i,\mu_{i} \ge 0$
Bonferroni方法拒绝全局零假设当
$$\max\limits_{i}Y_{i} \ge z(\alpha/n)，其中z(\alpha/n)是标准正态分布的上\alpha/n分位数$$

Thm:在全局零假设$H_{0}$下，$Y_{i}\overset{iid}{\sim} \mathcal{N}(o,1)$，我们有
$$
  \dfrac{\max Y_{i}}{\sqrt{ 2 \log n }} \overset{P}{\rightarrow}1
$$
proof:这里我用了大偏差理论中常用的Chernoff技巧证明了该渐进性态
$$
  P(\dfrac{\max Y_{i}}{\sqrt{2\log n}} \ge 1+\epsilon)
  =P(\max Y_{i} \ge (1+\epsilon)\sqrt{ 2 \log n })
  =P(\exp(\lambda \max Y_{i}) \ge \exp(\lambda (1+\epsilon)) \sqrt{ 2 \log n })
  \le e^{-\lambda (1+\epsilon) \sqrt{ 2 \log n }}Ee^{\lambda \max Y_{i}}
  \le e^{-\lambda (1+\epsilon) \sqrt{ 2 \log n }}n Ee^{\lambda Y_{1}}
  =e^{-\lambda (1+\epsilon) \sqrt{ 2 \log n }}n e^{\frac{1}{2}\lambda^2}，对\forall \lambda >0成立
  \le n e^{-\frac{1}{2}(1+\epsilon)^2 2\log n}，这里取了\lambda = (1+\epsilon)\sqrt{ 2 \log n }
  =n^{1-(1+\epsilon)^2}
  \to 0
$$
同理
$$
  P(\dfrac{\max Y_{i}}{\sqrt{2\log n}} \le 1-\epsilon)
  =P(\max Y_{i} \le (1-\epsilon)\sqrt{ 2 \log n })
  =P(\exp(-\lambda \max Y_{i}) \ge \exp(-\lambda (1-\epsilon)) \sqrt{ 2 \log n })
  \le e^{\lambda (1-\epsilon) \sqrt{ 2 \log n }}Ee^{-\lambda \max Y_{i}}
  \le e^{\lambda (1-\epsilon) \sqrt{ 2 \log n }}Ee^{-\lambda Y_{1}}
  =e^{\lambda (1-\epsilon) \sqrt{ 2 \log n }}e^{\frac{1}{2}\lambda^2}，对\forall \lambda >0成立
  \le e^{-\frac{1}{2}(1-\epsilon)^2 2\log n}，这里取了\lambda = -(1-\epsilon)\sqrt{ 2 \log n }
  =n^{-(1-\epsilon)^2}
  \to 0
$$



$$
  FDP = \dfrac{V}{\max(R,1)} = \left\{ 
  \begin{align} 
  \frac{V}{R}&,R \ge 1 \\
  0&,R=0
\end{align}
   \right.
$$
$FDP$代表了拒绝的假设中错误拒绝的比例。但是在这里，错误拒绝的假设的个数我们是不知道的，$FDP$并可以被直接观测到，所以我们尝试去控制$FDP$的期望，即错误发现率(FDR,false discovery rate)
$$
  FDR = E[FDP]  
$$

$$
    I_{\{V \ge 1\}} \ge \dfrac{V}{\max \{R,1\}}，其中I代表示性函数
$$
对上式两边取期望，可知$FWER\ge FDR$。所以控制$FDR$是多元假设检验中一个更加宽松的条件。利用$FWER$，很多时候就是“一刀切”，而考虑$FDR$我们可以在大样本中获得有用的信息。

BH(Benjamini-Hochberg)方法：
对于$n$个样本，显著性水平$\alpha$，我们考虑$n$个$p-values$.将这些$p-values$排好序，记为$p_{(1)} \le p_{{(2)}} \le \cdots \le p_{{(n)}}$
设$i_{0}$是最大的使得$p_{(i)} \le \frac{i}{n} \alpha$，BH方法拒绝所有的$H_{i},i \le i_{0}$


由经验分布函数看$BH_{\alpha}$方法：
$$
  \hat{F}_{n}(t)=\dfrac{\#\{i:p_{i}\le t\}}{n}  
$$
假设$p_{(1)} \le p_{{(2)}} \le \cdots \le p_{{(n)}}$，$BH_{\alpha}$方法拒绝$H_{0,i},1 \le i \le i_{0}$，其中$i_{0} = \max\left\{ i:p_{(i)} \le \frac{\alpha i}{n} \right\}$
$$
  p* \overset{def}{=} p_{i_{0}}
  =\max \left\{ p_{(i)}:p_{(i)}\le \frac{\alpha i}{n} \right\}
  =\max \left\{ p_{(i)}:p_{(i)}\le \alpha \hat{F}_{n}(p_{(i)}) \right\}
  =\max \left\{ t \in \{p_{1},\cdots,p_{n}\}: t \le \alpha \hat{F}_{n}(t) \right\}
  =\max \left\{ t \in \{p_{1},\cdots,p_{n}\}: \dfrac{t}{\hat{F}_{n}(t)} \le \alpha  \right\}
$$
我们把最后一步稍微完善一下，以防$\hat{F}_{n}(t)=0$不能作为分母。我们希望阈值$t$的选取不会太小，可以用$\hat{F}_{n}(t) \vee \frac{1}{n}$代替$\hat{F}_{n}(t)$。$BH_{\alpha}$方法等价于拒绝所有的$H_{0,i}$，如果对应的$p_{i} \le \tau_{BH}$:
$$
  \tau_{BH} \overset{def}{=} \max \left\{t: \dfrac{t}{\hat{F}_{n}(t) \vee \frac{1}{n}}\right\} 
$$
注意到
$$
    \dfrac{t}{\hat{F}_{n}(t) \vee \frac{1}{n}}
    =\dfrac{nt}{n\hat{F}_{n}(t) \vee 1 }
    =\dfrac{nt}{R(t) \vee 1}
$$
而
$$
  FDR(t) =E\left\{ \dfrac{V(t)}{R(t) \vee 1} \right\} 
  =\dfrac{n_{0} t}{R(t) \vee 1}
$$
这里$n_{0}$是未知的常量，不是随机变量。为了控制$FDR(t)$，我们可以采用保守的$\widehat{FDR}(t) = \dfrac{n t}{R(t) \vee 1}$作为$FDR$的估计。到此，我们可以对$BH_{\alpha}$方法中的$\tau_{BH}$做出如下解释：
我们要控制$\widehat{FDR}(t)$的值不超过显著性水平$\alpha$，同时呢，为了提高检验效率，我们希望阈值$t$尽可能大，因此我们定义阈值$\tau_{BH}$，为了方便，以下记为$\tau$
def
$$
  \tau = \sup \left\{t\le 1: \dfrac{nt}{V(t) \vee 1} \le \alpha \right\} 
$$




BH
由BH方法，我们拒绝所有的满足$p_{i} \le \tau$的假设，此时可以控制$FDR$如下：
$$
  E[FDR(\tau)]=\frac{\alpha n_{0}}{n}  
$$
proof
我们利用了连续时间鞅中的Doob's可选停时定理
定义一个域流
$$
  \mathcal{F}_{t}=\sigma(V(s),R(s):t \le s \le 1)  
$$
注意到，这是一个倒退的域流：$\forall t_{1} < t_{2},\mathcal{F}_{t_{2}} \subset \mathcal{F}_{t_{1}}$
定义倒退的鞅(reverse martingale)$V(t)/t,0 \le t \leq 1$
证明这是一个鞅：对于$s \le t$
(1)$V(t)/t$显然适应于域流$\mathcal{F}_{t}$
(2)可积性是显然的，因为$V(t)/t \le n/t$
(3)
$$
  E\left[\dfrac{V(s)}{s}|\mathcal{F}_{t}\right]
  =\dfrac{1}{s}E\left[V(s)|\mathcal{F}_{t}\right]
  =\dfrac{1}{s} \cdot \dfrac{s}{t} V(t)
  =\dfrac{V(t)}{t}
$$
这里的第二个等号是因为在已知$V(t)$的情况下，$H_{0,i}$为真时，$p_{i} \sim U[0,t]$，且$H_{0,i}$之间都是独立的。


因此$\{V(t)/t,0 \le t \le 1 \}$是一个鞅。
$\tau$是一个停时：
$$
\left\{ \tau \le t  \right\} = \bigcap\limits_{s > t}\left\{ \dfrac{ns}{R(s) \vee 1} > \alpha \right\} \in \mathcal{F}_{t}
$$


claim(自己)：$R(\tau) \vee 1 = \dfrac{n\tau}{\alpha}$，其中$\tau = \sup \left\{t\le 1: \dfrac{nt}{R(t) \vee 1} \le \alpha \right\}$
(1)$\tau$满足$\dfrac{nt}{R(t) \vee 1} \ge \alpha$:
反证，假设$\dfrac{nt}{R(t) \vee 1} < \alpha$，由右连续性，可知$\tau$不是上确界，矛盾
(2)$\tau$满足$\dfrac{nt}{R(t) \vee 1} \le \alpha$:
$\exists t_{k} \uparrow \tau$，$t_{k}$满足$\dfrac{nt_{k}}{R(t) \vee 1} \leq \alpha$
如果$R(t) \vee 1$在$\tau$处连续，证毕
如果$R(t) \vee 1$在$\tau$处不连续，那么$R(\tau) \vee 1 \le (R(t_{k}) \vee 1) +1$，从而得$\dfrac{nt}{R(t) \vee 1} \le \alpha$



对于鞅$\{V(t)/t,0 \le t \le 1 \}$和停时$\tau$，利用Doob's可选停时定理以及上面的claim，可得：
$$
  FDR(\tau) = E\left[ \dfrac{V(t)}{R(t) \vee 1} \right]
  = \dfrac{\alpha}{n}E\left[ \dfrac{V(\tau)}{\tau } \right]
  = \dfrac{\alpha}{n}E\left[ \dfrac{V(1)}{1 } \right]
  = \dfrac{\alpha}{n} \cdot n_{0}
$$



Storey方法：
$$
  \tau = \sup \left\{t\le \dfrac{1}{2}:\widehat{FDR}(t)=\dfrac{1+n-R(1/2)}{n/2} \cdot \dfrac{nt}{V(t) \vee 1} \le \alpha \right\} 
$$

Storey方法的统计学意义：
在BH方法中，我们是用$\dfrac{nt}{V(t) \vee 1}$对$FDR$做的保守估计，然而，我们可以有更加精细的估计：
$$
    \widehat{FDR}^\lambda(t) = \hat{\pi}_{0}^\lambda \cdot \dfrac{nt}{V(t) \vee 1}
$$
其中系数$\hat{\pi}_{0}^\lambda = \dfrac{n - R(\lambda)}{(1-\lambda)n}$是对未知常数$\dfrac{n_{0}}{n}$的估计，$R(\lambda) = \#\{i:p_{i} \le \lambda\}$
我们可以设想，非零假设的$p-value$都是比较小的，所以比$\lambda$大的$p-value$都来源于零假设。而零假设的$p-value$服从均匀分布，因此有
$$
  n-R(\lambda) \approx n \pi_{0}(1-\lambda),\pi_{0}=\dfrac{n_{0}}{n}
$$
$\hat{\pi}_{0}^\lambda$是对$\pi_{0}$的估计

$\lambda$的选取是一个比较大的课题，需要考虑$MSE = bias^2 + Var$，Storey方法选取的是$\lambda = \dfrac{1}{2}$


Storey方法与鞅：
Thm:$FDR(\tau) \le q$
类似于上文BH方法FDR控制中的证明，我们利用了Doob's可选停时原理以及如下性质：
(1)$\left\{\dfrac{V(t)}{t}:t\in [0,1/2] \right\}$是鞅
(2)$\tau$是停时
(3)$\widehat{FDR}(\tau) = q$
Proof:
$$
  \begin{align}
FDR(\tau) &= E\left[ \dfrac{V(t)}{R(t) \vee 1} \right] \\
&=E\left[ \dfrac{V(\tau)}{n\tau} \cdot \dfrac{n\tau}{V(\tau) \vee 1} \cdot \dfrac{1+n-R(1/2)}{n/2} \cdot \dfrac{n/2}{1+n-R(1/2)} \right] \\
&=E\left[ \widehat{FDR}(\tau) \cdot \dfrac{V(\tau)}{n\tau}\cdot \dfrac{n/2}{1+n-R(1/2)} \right] \\
&=\alpha \cdot E\left[ \dfrac{V(\tau)}{\tau}\cdot \dfrac{1/2}{1+n-R(1/2)} \right] \\
&=\alpha \cdot E\left[ \dfrac{V(1/2)}{1/2}\cdot \dfrac{1/2}{1+n-R(1/2)} \right] \\
&=\alpha \cdot E\left[ \dfrac{V(1/2)}{1+n-R(1/2)} \right]  \\
&\le q \cdot E\left[ \dfrac{V(1/2)}{1+n_{0}-V(1/2)} \right]
\end{align}  
$$
注意到，$V(1/2) \sim B(n_{0},1/2)$，$B(n_{0},1/2)$是二项分布
$$
  \begin{align}
E\left[ \dfrac{V(1/2)}{1+n_{0}-V(1/2)} \right]&=\sum\limits_{ i = 1 }^{ n_{0} }P(V(1/2)=i) \cdot \dfrac{i}{1+n_{0}-i} \\
&=2^{-n_{0}}\sum\limits_{ i = 1 }^{ n_{0} }{n_0 \choose i} \cdot \dfrac{i}{1+n_{0} -i} \\
&=2^{-n_{0}}\sum\limits_{ i = 1 }^{ n_{0} } \dfrac{n_{0}!}{(n_{0}-i+1)!(i-1)!} \\
&=2^{-n_{0}}\sum\limits_{ i = 1 }^{ n_{0}-1 } {n_{0} \choose j} \\
&=2^{-n_{0}}(2^{n_{0}}-1) \\
&\le 1
\end{align}  
$$
证毕